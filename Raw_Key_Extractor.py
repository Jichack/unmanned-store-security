import os
import cv2
import numpy as np
import torch
from ultralytics import YOLO
from tqdm import tqdm
from collections import defaultdict
import gc

# === ì„¤ì • ===
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_ROOT = os.path.join(BASE_DIR, 'dataset')
RAW_SAVE_PATH = os.path.join(BASE_DIR, 'raw_data') # ì¤‘ê°„ ì €ì¥ì†Œ

# YOLO ëª¨ë¸ ì„¤ì • (GPU ê¶Œì¥)
MODEL_PATH = 'yolo11n-pose.pt'
IMGSZ = 640  # ì†ë„ë¥¼ ë†’ì´ë ¤ë©´ 320ìœ¼ë¡œ ì¤„ì—¬ë„ ë¨
CONF_THRES = 0.3 # ë‚˜ì¤‘ì— ë§ˆìŠ¤í‚¹ í• ê±°ë‹ˆê¹Œ ì¢€ ë‚®ê²Œ ì„¤ì •í•´ì„œ ë‹¤ ì¡ìŒ

def extract_raw_skeleton(video_path, save_path):
    # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì´ë©´ ìŠ¤í‚µ (ì´ì–´í•˜ê¸° ê¸°ëŠ¥)
    if os.path.exists(save_path):
        return
        
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened(): return
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30.0

    # ëª¨ë¸ ë¡œë“œ (í•¨ìˆ˜ ì•ˆì—ì„œ ë¡œë“œí•˜ë©´ ë©”ëª¨ë¦¬ ë‚­ë¹„ë  ìˆ˜ ìˆìœ¼ë‚˜, ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¼ ê°€ì •)
    model = YOLO(MODEL_PATH) 
    
    # IDë³„ íŠ¸ë™ ì €ì¥
    tracks = defaultdict(dict)
    
    # YOLO ì¶”ë¡  (Stream ëª¨ë“œ ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
    # verbose=Falseë¡œ ë¡œê·¸ ë”
    results = model.track(source=video_path, stream=True, persist=True, 
                          imgsz=IMGSZ, conf=CONF_THRES, verbose=False, vid_stride=1)
    
    for frame_idx, result in enumerate(results):
        if result.boxes.id is not None:
            ids = result.boxes.id.cpu().numpy().astype(int)
            kps = result.keypoints.data.cpu().numpy() # (N, 17, 3) (x, y, conf)
            
            for i, track_id in enumerate(ids):
                # ì •ê·œí™” í•˜ì§€ ì•Šì€ ì›ë³¸ ì¢Œí‘œ ì €ì¥ (ë‚˜ì¤‘ì— ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ í•¨)
                tracks[track_id][frame_idx] = kps[i]
                
    cap.release()
    
    # [ê°€ì¥ í™œë™ì ì¸ ì‚¬ëŒ 1ëª… ì„ ì •]
    if not tracks:
        return # ê°ì§€ëœ ì‚¬ëŒ ì—†ìŒ

    best_track_id = -1
    max_score = -1
    
    for track_id, data_dict in tracks.items():
        # ë„ˆë¬´ ì§§ì€ íŠ¸ë™(ì „ì²´ì˜ 10% ë¯¸ë§Œ) ì œì™¸
        if len(data_dict) < total_frames * 0.1: continue
        
        sorted_indices = sorted(data_dict.keys())
        valid_kps = np.array([data_dict[t] for t in sorted_indices])
        
        # ì›€ì§ì„ ì ìˆ˜ ê³„ì‚°
        movement_score = 0
        if len(valid_kps) > 1:
            diff = valid_kps[1:, :, :2] - valid_kps[:-1, :, :2]
            dist = np.sqrt(np.sum(diff**2, axis=2))
            movement_score = np.sum(dist)
            
        # ì§€ì† ì‹œê°„ + ì›€ì§ì„
        total_score = movement_score + (len(valid_kps) * 0.5)
        
        if total_score > max_score:
            max_score = total_score
            best_track_id = track_id
            
    if best_track_id == -1: return

    # [ì €ì¥ í¬ë§·]
    # (Total_Frames, 17, 3)ì˜ Denseí•œ ë°°ì—´ì„ ë§Œë“¦. ê°ì§€ ì•ˆ ëœ ê³³ì€ 0ìœ¼ë¡œ ì±„ì›€.
    # ì´ë ‡ê²Œ í•´ì•¼ ë‚˜ì¤‘ì— ì¸ë±ì‹±í•˜ê¸° í¸í•¨.
    final_array = np.zeros((total_frames, 17, 3), dtype=np.float32)
    best_data = tracks[best_track_id]
    
    for t, kp in best_data.items():
        if t < total_frames:
            final_array[t] = kp
            
    # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥ (Dictionary)
    save_data = {
        'fps': fps,
        'width': width,
        'height': height,
        'keypoints': final_array # (T, 17, 3)
    }
    
    np.save(save_path, save_data)
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del model, tracks, results, final_array
    gc.collect()
    torch.cuda.empty_cache() 

def main():
    os.makedirs(RAW_SAVE_PATH, exist_ok=True)
    
    video_files = []
    for root, dirs, files in os.walk(DATASET_ROOT):
        for file in files:
            if file.endswith(('.mp4', '.avi')):
                video_files.append(os.path.join(root, file))
    
    print(f"ğŸš€ Step 1 ì‹œì‘: ì´ {len(video_files)}ê°œ ì˜ìƒ ì²˜ë¦¬")
    print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {RAW_SAVE_PATH}")
    print("â„¹ï¸  ì´ ì‘ì—…ì€ ì˜¤ë˜ ê±¸ë¦¬ì§€ë§Œ, ì¤‘ê°„ì— êº¼ë„ ë‹¤ì‹œ ì¼œë©´ ì´ì–´ì„œ í•©ë‹ˆë‹¤.")

    # GPU í•˜ë‚˜ë§Œ ì“´ë‹¤ë©´ ê·¸ëƒ¥ ìˆœì°¨ ì²˜ë¦¬ê°€ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.
    # ë©€í‹°í”„ë¡œì„¸ì‹± í•˜ë ¤ë©´ GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ë³µì¡í•´ì§.
    for video_path in tqdm(video_files):
        file_name = os.path.splitext(os.path.basename(video_path))[0]
        save_path = os.path.join(RAW_SAVE_PATH, file_name + '.npy')
        
        try:
            extract_raw_skeleton(video_path, save_path)
        except Exception as e:
            print(f"\nError processing {file_name}: {e}")

if __name__ == "__main__":
    main()