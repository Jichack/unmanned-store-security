{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNT4AJw92IXBfqAXe4dRBVf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iXe3IWaXYStL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4588fe2-637d-4cef-ffc4-f111cdf8281e"},"outputs":[{"output_type":"stream","name":"stdout","text":["â–¶ í˜„ì¬ ì„ íƒëœ ëª¨ë¸: STGCN\n","â–¶ ë°ì´í„° ë¡œë”©...\n","\n","ğŸš€ ì´ 5íšŒ ë°˜ë³µ ì‹¤í—˜ ì‹œì‘ (STGCN Model)\n","------------------------------------------------------------\n","ğŸ”„ Run 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 1] Ep 01 | Loss: 0.8479 | Train Acc: 58.32% | Val Acc: 54.55%\n","      â””â”€â”€ Best Val Updated! (54.55%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 1] Ep 02 | Loss: 0.6277 | Train Acc: 71.21% | Val Acc: 67.28%\n","      â””â”€â”€ Best Val Updated! (67.28%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 1] Ep 03 | Loss: 0.5489 | Train Acc: 74.90% | Val Acc: 80.39%\n","      â””â”€â”€ Best Val Updated! (80.39%)\n","\n","   âœ… Run 1 Finished. Final Best: 80.39%\n","   âœ… Run 1 Summary | Best Val: 80.39% | Fall Recall: 0.8390\n","------------------------------------------------------------\n","ğŸ”„ Run 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 2] Ep 01 | Loss: 0.8526 | Train Acc: 59.75% | Val Acc: 59.92%\n","      â””â”€â”€ Best Val Updated! (59.92%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 2] Ep 02 | Loss: 0.6330 | Train Acc: 71.73% | Val Acc: 61.77%\n","      â””â”€â”€ Best Val Updated! (61.77%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 2] Ep 03 | Loss: 0.5532 | Train Acc: 75.39% | Val Acc: 66.94%\n","      â””â”€â”€ Best Val Updated! (66.94%)\n","\n","   âœ… Run 2 Finished. Final Best: 66.94%\n","   âœ… Run 2 Summary | Best Val: 66.94% | Fall Recall: 0.8694\n","------------------------------------------------------------\n","ğŸ”„ Run 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 3] Ep 01 | Loss: 0.8520 | Train Acc: 57.61% | Val Acc: 47.08%\n","      â””â”€â”€ Best Val Updated! (47.08%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 3] Ep 02 | Loss: 0.6207 | Train Acc: 71.78% | Val Acc: 66.45%\n","      â””â”€â”€ Best Val Updated! (66.45%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 3] Ep 03 | Loss: 0.5352 | Train Acc: 75.75% | Val Acc: 79.63%\n","      â””â”€â”€ Best Val Updated! (79.63%)\n","\n","   âœ… Run 3 Finished. Final Best: 79.63%\n","   âœ… Run 3 Summary | Best Val: 79.63% | Fall Recall: 0.7650\n","------------------------------------------------------------\n","ğŸ”„ Run 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 4] Ep 01 | Loss: 0.8667 | Train Acc: 57.18% | Val Acc: 70.55%\n","      â””â”€â”€ Best Val Updated! (70.55%)\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 4] Ep 02 | Loss: 0.6163 | Train Acc: 71.00% | Val Acc: 51.03%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["   [Run 4] Ep 03 | Loss: 0.5354 | Train Acc: 74.97% | Val Acc: 71.14%\n","      â””â”€â”€ Best Val Updated! (71.14%)\n","\n","   âœ… Run 4 Finished. Final Best: 71.14%\n","   âœ… Run 4 Summary | Best Val: 71.14% | Fall Recall: 0.8444\n","------------------------------------------------------------\n","ğŸ”„ Run 5/5\n"]},{"output_type":"stream","name":"stderr","text":["   Epoch 1/3:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 998/1595 [00:22<00:11, 51.08it/s, acc=54.93%, loss=0.6705]"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","import os\n","from google.colab import drive\n","from tqdm import tqdm\n","import collections\n","\n","# === 1. ì„¤ì • ===\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","\n","ROOT_PATH = '/content/drive/MyDrive/Capstone_Project'\n","DATA_PATH = os.path.join(ROOT_PATH, 'processed_data', 'train_data_30_10.npy')\n","LABEL_PATH = os.path.join(ROOT_PATH, 'processed_data', 'train_label_30_10.npy')\n","MODEL_SAVE_BASE = os.path.join(ROOT_PATH, 'experiment_full_metric')\n","\n","CLASSES = ['Walking', 'Shopping', 'Falldown', 'Threat']\n","BATCH_SIZE = 32\n","EPOCHS = 3\n","LEARNING_RATE = 0.01\n","NUM_RUNS = 5\n","step_size = 15\n","\n","# â˜…â˜…â˜… ëª¨ë¸ ì„ íƒ ìŠ¤ìœ„ì¹˜ (ì—¬ê¸°ë§Œ ë°”ê¾¸ì„¸ìš”!) â˜…â˜…â˜…\n","# 'stgcn' ë˜ëŠ” 'lstm'\n","MODEL_TYPE = 'stgcn'\n","print(f\"â–¶ í˜„ì¬ ì„ íƒëœ ëª¨ë¸: {MODEL_TYPE.upper()}\")\n","\n","\n","# === 2. ë°ì´í„° ë¡œë“œ ===\n","print(\"â–¶ ë°ì´í„° ë¡œë”©...\")\n","X = np.load(DATA_PATH)\n","Y = np.load(LABEL_PATH)\n","\n","class_weights = compute_class_weight('balanced', classes=np.unique(Y), y=Y)\n","class_weights = torch.tensor(class_weights, dtype=torch.float32)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# === 3. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ë‘ ëª¨ë¸ ëª¨ë‘ í¬í•¨) ===\n","\n","# [3-1] ST-GCN ê´€ë ¨ í´ë˜ìŠ¤\n","class Graph:\n","    def __init__(self, num_node=17):\n","        self.num_node = num_node\n","        self.edges = [(0,1),(0,2),(1,3),(2,4),(5,7),(7,9),(6,8),(8,10),(5,6),(5,11),(6,12),(11,12),(11,13),(13,15),(12,14),(14,16)]\n","        self.A = self.get_adjacency_matrix(self.edges, self.num_node)\n","    def get_adjacency_matrix(self, edges, num_node):\n","        A = np.zeros((num_node, num_node))\n","        for i in range(num_node): A[i, i] = 1\n","        for edge in edges:\n","            A[edge[0], edge[1]] = 1\n","            A[edge[1], edge[0]] = 1\n","        row_sum = np.sum(A, axis=1)\n","        D_inv_sqrt = np.power(row_sum, -0.5)\n","        D_inv_sqrt[np.isinf(D_inv_sqrt)] = 0.\n","        D_mat = np.diag(D_inv_sqrt)\n","        return torch.tensor(D_mat.dot(A).dot(D_mat), dtype=torch.float32)\n","\n","class STGCNBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, A, stride=1, residual=True):\n","        super().__init__()\n","        self.A = A\n","        self.gcn = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","        self.tcn = nn.Sequential(\n","            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=(9,1), padding=(4,0), stride=(stride,1)),\n","            nn.BatchNorm2d(out_channels), nn.Dropout(0.5, inplace=True)\n","        )\n","        if not residual: self.residual_conv = lambda x: 0\n","        elif (in_channels == out_channels) and (stride == 1): self.residual_conv = lambda x: x\n","        else: self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride,1))\n","    def forward(self, x):\n","        x_spatial = self.gcn(x)\n","        N, C, T, V = x_spatial.size()\n","        x_spatial = torch.matmul(x_spatial.view(N, C*T, V), self.A.to(x.device)).view(N, C, T, V)\n","        return torch.relu(self.tcn(x_spatial) + self.residual_conv(x))\n","\n","class STGCN_Model(nn.Module):\n","    def __init__(self, num_classes, in_channels=3, num_frames=30, num_joints=17):\n","        super().__init__()\n","        graph = Graph(num_node=num_joints)\n","        self.A = nn.Parameter(graph.A, requires_grad=False)\n","        self.data_bn = nn.BatchNorm1d(in_channels * num_joints)\n","\n","        # Half-STGCN (ê²½ëŸ‰í™”)\n","        self.st_gcn_networks = nn.Sequential(\n","            STGCNBlock(in_channels, 32, self.A),\n","            STGCNBlock(32, 32, self.A),\n","            STGCNBlock(32, 32, self.A),\n","            STGCNBlock(32, 64, self.A, stride=2),\n","            STGCNBlock(64, 64, self.A),\n","            STGCNBlock(64, 64, self.A),\n","            STGCNBlock(64, 128, self.A, stride=2),\n","            STGCNBlock(128, 128, self.A),\n","            STGCNBlock(128, 128, self.A)\n","        )\n","        self.fcn = nn.Conv2d(128, num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        N, C, T, V, M = x.size()\n","        x = x.mean(dim=4) # (N, C, T, V)\n","        x = x.permute(0, 1, 3, 2).contiguous().view(N, C*V, T)\n","        x = self.data_bn(x)\n","        x = x.view(N, C, V, T).permute(0, 1, 3, 2).contiguous()\n","        x = self.st_gcn_networks(x)\n","        x = torch.nn.functional.avg_pool2d(x, x.size()[2:])\n","        return self.fcn(x).view(x.size(0), -1)\n","\n","# [3-2] LSTM ê´€ë ¨ í´ë˜ìŠ¤\n","class LSTM_Model(nn.Module):\n","    def __init__(self, num_classes, input_size=34, hidden_size=128, num_layers=2):\n","        super(LSTM_Model, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        # x shape: (N, C, T, V, M)\n","        N, C, T, V, M = x.size()\n","        x = x.permute(0, 2, 3, 1, 4).contiguous() # (N, T, V, C, M)\n","        x = x.view(N, T, -1)  # (N, T, Features) Flatten\n","\n","        lstm_out, _ = self.lstm(x)\n","        last_output = lstm_out[:, -1, :]\n","        return self.fc(last_output)\n","\n","\n","# === 4. ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™” ===\n","metrics_storage = {cls: {'precision': [], 'recall': [], 'f1-score': []} for cls in CLASSES}\n","metrics_storage['Overall'] = {'accuracy': []}\n","all_history = {'train_loss': [], 'train_acc': [], 'val_acc': []}\n","confusion_preds, confusion_labels = [], []\n","\n","print(f\"\\nğŸš€ ì´ {NUM_RUNS}íšŒ ë°˜ë³µ ì‹¤í—˜ ì‹œì‘ ({MODEL_TYPE.upper()} Model)\")\n","\n","for run in range(1, NUM_RUNS + 1):\n","    print(\"-\" * 60)\n","    print(f\"ğŸ”„ Run {run}/{NUM_RUNS}\")\n","\n","    current_seed = 42 + run\n","    torch.manual_seed(current_seed)\n","    np.random.seed(current_seed)\n","\n","    X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=current_seed, stratify=Y)\n","\n","    train_data = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n","    val_data = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n","\n","    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","    # â˜…â˜…â˜… ëª¨ë¸ ì´ˆê¸°í™” ë¶„ê¸° ë¡œì§ (ì¤‘ìš”!) â˜…â˜…â˜…\n","    if MODEL_TYPE.lower() == 'stgcn':\n","        # ST-GCNì€ ì±„ë„ ìˆ˜(C)ê°€ ì¤‘ìš” (ë³´í†µ 3: x,y,score)\n","        in_channels = X_train.shape[1]\n","        model = STGCN_Model(num_classes=len(CLASSES), in_channels=in_channels).to(device)\n","    else:\n","        # LSTMì€ Flattenëœ Feature Sizeê°€ ì¤‘ìš” (C * V)\n","        input_dim = X_train.shape[1] * X_train.shape[3]\n","        model = LSTM_Model(num_classes=len(CLASSES), input_size=input_dim).to(device)\n","\n","    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1)\n","\n","    best_acc = 0.0\n","    best_model_path = f\"{MODEL_SAVE_BASE}_{MODEL_TYPE}_{run}.pth\" # ì €ì¥ëª…ì— ëª¨ë¸íƒ€ì… ì¶”ê°€\n","\n","    run_train_losses = []\n","    run_train_accs = []\n","    run_val_accs = []\n","\n","    # === í•™ìŠµ ë£¨í”„ ===\n","    for epoch in range(EPOCHS):\n","        model.train()\n","        running_loss = 0.0\n","        train_correct = 0\n","        train_total = 0\n","\n","        train_loop = tqdm(train_loader, desc=f\"   Epoch {epoch+1}/{EPOCHS}\", leave=False)\n","\n","        for inputs, labels in train_loop:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_total += labels.size(0)\n","            train_correct += (predicted == labels).sum().item()\n","\n","            train_loop.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100.*train_correct/train_total:.2f}%\")\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","        avg_train_acc = 100 * train_correct / train_total\n","\n","        model.eval()\n","        val_correct, val_total = 0, 0\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                _, predicted = torch.max(outputs.data, 1)\n","                val_total += labels.size(0)\n","                val_correct += (predicted == labels).sum().item()\n","\n","        val_acc = 100 * val_correct / val_total\n","        scheduler.step()\n","\n","        run_train_losses.append(avg_train_loss)\n","        run_train_accs.append(avg_train_acc)\n","        run_val_accs.append(val_acc)\n","\n","        print(f\"   [Run {run}] Ep {epoch+1:02d} | Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n","\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            torch.save(model.state_dict(), best_model_path)\n","            print(f\"      â””â”€â”€ Best Val Updated! ({best_acc:.2f}%)\")\n","\n","    all_history['train_loss'].append(run_train_losses)\n","    all_history['train_acc'].append(run_train_accs)\n","    all_history['val_acc'].append(run_val_accs)\n","\n","    # === í‰ê°€ ë° ì €ì¥ ===\n","    print(f\"\\n   âœ… Run {run} Finished. Final Best: {best_acc:.2f}%\")\n","    model.load_state_dict(torch.load(best_model_path))\n","    model.eval()\n","\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.numpy())\n","\n","    confusion_preds.extend(all_preds)\n","    confusion_labels.extend(all_labels)\n","\n","    report = classification_report(all_labels, all_preds, target_names=CLASSES, output_dict=True)\n","    metrics_storage['Overall']['accuracy'].append(report['accuracy'])\n","    for cls in CLASSES:\n","            metrics_storage[cls]['precision'].append(report[cls]['precision'])\n","            metrics_storage[cls]['recall'].append(report[cls]['recall'])\n","            metrics_storage[cls]['f1-score'].append(report[cls]['f1-score'])\n","\n","    print(f\"   âœ… Run {run} Summary | Best Val: {best_acc:.2f}% | Fall Recall: {report['Falldown']['recall']:.4f}\")\n","\n","# === 5. ìµœì¢… ë¦¬í¬íŠ¸ ë° ì‹œê°í™” ===\n","print(\"\\n\" + \"=\" * 80)\n","print(f\"ğŸ“Š {MODEL_TYPE.upper()} Model - {NUM_RUNS}íšŒ ë°˜ë³µ ì‹¤í—˜ ì¢…í•© ê²°ê³¼\")\n","print(\"=\" * 80)\n","\n","acc_mean = np.mean(metrics_storage['Overall']['accuracy']) * 100\n","acc_std = np.std(metrics_storage['Overall']['accuracy']) * 100\n","print(f\"ğŸ† Overall Accuracy: {acc_mean:.2f} Â± {acc_std:.2f}%\")\n","\n","header = f\"{'Class':<12} | {'Metric':<10} | {'Mean':<8} | {'Std':<8}\"\n","print(\"-\" * 45)\n","print(header)\n","print(\"-\" * 45)\n","for cls in CLASSES:\n","    for metric in ['precision', 'recall', 'f1-score']:\n","        values = metrics_storage[cls][metric]\n","        print(f\"{cls:<12} | {metric.capitalize():<10} | {np.mean(values):.4f}   | Â±{np.std(values):.4f}\")\n","    print(\"-\" * 45)\n","\n","# === 6. ê·¸ë˜í”„ ê·¸ë¦¬ê¸° ===\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","mean_loss = np.mean(all_history['train_loss'], axis=0)\n","std_loss = np.std(all_history['train_loss'], axis=0)\n","epochs = range(1, EPOCHS + 1)\n","plt.plot(epochs, mean_loss, 'b-', label='Training Loss')\n","plt.fill_between(epochs, mean_loss - std_loss, mean_loss + std_loss, color='b', alpha=0.2)\n","plt.title(f'Training Loss ({MODEL_TYPE.upper()})')\n","plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n","\n","plt.subplot(1, 2, 2)\n","mean_train_acc = np.mean(all_history['train_acc'], axis=0)\n","mean_val_acc = np.mean(all_history['val_acc'], axis=0)\n","plt.plot(epochs, mean_train_acc, 'b-', label='Train Acc')\n","plt.plot(epochs, mean_val_acc, 'r-', label='Val Acc')\n","plt.title(f'Accuracy ({MODEL_TYPE.upper()})')\n","plt.xlabel('Epochs'); plt.ylabel('Accuracy (%)'); plt.legend(); plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# === 7. í˜¼ëˆ í–‰ë ¬ ===\n","plt.figure(figsize=(8, 6))\n","cm = confusion_matrix(confusion_labels, confusion_preds)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n","plt.title(f'Confusion Matrix ({MODEL_TYPE.upper()})')\n","plt.ylabel('True Label'); plt.xlabel('Predicted Label')\n","plt.show()\n","\n","print(\"\\nâœ… ì™„ë£Œ! ëª¨ë¸ ë³€ê²½ ì‹œ ë§¨ ìœ„ 'MODEL_TYPE' ë³€ìˆ˜ë§Œ ë°”ê¾¸ì„¸ìš”.\")"]}]}